<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2018-08-15 Wed 11:02 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Operating Systems</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Jethro Kuan" />
<link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/readtheorg/js/readtheorg.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Operating Systems</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orge97fe1c">1. Operating System Key Concepts</a>
<ul>
<li><a href="#org326f8be">1.1. Motivation</a></li>
<li><a href="#org99974eb">1.2. Alarm signal</a></li>
<li><a href="#orgc52533b">1.3. Identification</a></li>
<li><a href="#org2d01dce">1.4. File systems</a></li>
<li><a href="#orga1ebde5">1.5. Pipe</a></li>
<li><a href="#org185874f">1.6. Process segments</a></li>
<li><a href="#orgb4c62ae">1.7. Files in UNIX</a></li>
<li><a href="#org5157deb">1.8. Hypervisors</a></li>
</ul>
</li>
<li><a href="#org1b901ec">2. Process</a>
<ul>
<li><a href="#org3115663">2.1. Process Creation</a></li>
<li><a href="#org37ce3fd">2.2. Function Call</a>
<ul>
<li><a href="#org1dfd722">2.2.1. Control Flow issues</a></li>
<li><a href="#org42359a1">2.2.2. Data Storage issues</a></li>
<li><a href="#orgfd7fc51">2.2.3. Stack Memory</a></li>
<li><a href="#orge0acd05">2.2.4. Stack Frame</a></li>
<li><a href="#orgafd00d6">2.2.5. Function Call Convention (FCC)</a></li>
<li><a href="#org27d103d">2.2.6. Frame Pointer</a></li>
</ul>
</li>
<li><a href="#org41b1455">2.3. Dynamic Memory Allocation</a></li>
<li><a href="#org7a1bae6">2.4. Process Identification</a></li>
<li><a href="#orgd7f2900">2.5. 5-state Process Model</a></li>
<li><a href="#org0cb829b">2.6. Data structures required</a></li>
<li><a href="#org5cff88f">2.7. Mechanism: Limited Direct Execution</a></li>
<li><a href="#org6001bec">2.8. Access Control</a></li>
<li><a href="#org8f08f41">2.9. General System Call Mechanism</a></li>
<li><a href="#orgdc46852">2.10. Switching between processes</a>
<ul>
<li><a href="#orgb88a87d">2.10.1. Cooperative Approach</a></li>
<li><a href="#org16728aa">2.10.2. Non-cooperative Approach</a></li>
</ul>
</li>
<li><a href="#orgbbfbc5a">2.11. Exception and Interrupts</a></li>
</ul>
</li>
<li><a href="#org5bc59b6">3. Scheduling</a>
<ul>
<li><a href="#orgeb44108">3.1. Scheduling Metrics</a></li>
<li><a href="#org3c33b5a">3.2. First Come First Served (FCFS)</a>
<ul>
<li><a href="#orgd92c11e">3.2.1. Pros</a></li>
<li><a href="#org74b5b1a">3.2.2. Cons</a></li>
</ul>
</li>
<li><a href="#orge91f610">3.3. Shortest Job First (SJF)</a>
<ul>
<li><a href="#org76b749f">3.3.1. Pros</a></li>
<li><a href="#orgdfd533f">3.3.2. Cons</a></li>
</ul>
</li>
<li><a href="#org5386958">3.4. Shortest Time-to-Completion First (SRT)</a>
<ul>
<li><a href="#org008004e">3.4.1. Pros</a></li>
<li><a href="#org3b29230">3.4.2. Cons</a></li>
</ul>
</li>
<li><a href="#org54533f3">3.5. Round Robin</a>
<ul>
<li><a href="#org2af9825">3.5.1. Incorporating I/O</a></li>
</ul>
</li>
<li><a href="#org15c9010">3.6. Multi-level Feedback Queue (MLFQ)</a>
<ul>
<li><a href="#orgfa6ee25">3.6.1. Tuning MLFQ</a></li>
</ul>
</li>
<li><a href="#orgc03da43">3.7. Lottery Scheduling</a></li>
</ul>
</li>
<li><a href="#orgcdeb605">4. Concurrency</a></li>
<li><a href="#org4403a85">5. Thread</a>
<ul>
<li><a href="#org5966dc7">5.1. Example Thread creation</a></li>
<li><a href="#org8a57f37">5.2. Issues with Uncontrolled Scheduling</a>
<ul>
<li><a href="#org8eb67c8">5.2.1. Race Condition</a></li>
<li><a href="#org25851c7">5.2.2. Key Terms</a></li>
<li><a href="#org1db2fcb">5.2.3. The wish for atomicity</a></li>
</ul>
</li>
<li><a href="#orgbd56ead">5.3. Thread API</a>
<ul>
<li><a href="#orgf667ce8">5.3.1. Locks API</a></li>
<li><a href="#org9871092">5.3.2. Condition Variables</a></li>
</ul>
</li>
<li><a href="#org5f3e9f8">5.4. Properties of Correct CS Implementation</a></li>
<li><a href="#orgc92dd40">5.5. Locks</a>
<ul>
<li><a href="#org529562a">5.5.1. Pthread Locks</a></li>
<li><a href="#orge41ed99">5.5.2. Evaluating locks</a></li>
<li><a href="#orgab70f97">5.5.3. Approach 1: Controlling Interrupts</a>
<ul>
<li><a href="#orgd49da64">5.5.3.1. Pros</a></li>
<li><a href="#org59fb683">5.5.3.2. Cons</a></li>
</ul>
</li>
<li><a href="#org37061f4">5.5.4. Approach 2: Test and Set</a>
<ul>
<li><a href="#org15a019c">5.5.4.1. Evaluating the spin lock:</a></li>
</ul>
</li>
<li><a href="#org187258a">5.5.5. Two Phase Locks</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org58ce580">6. Classical Synchronization Problems</a>
<ul>
<li><a href="#org036135b">6.1. Producer/Consumer</a></li>
<li><a href="#orgbba733c">6.2. Readers/Writers</a></li>
<li><a href="#org0b02dae">6.3. Dining Philosophers</a>
<ul>
<li><a href="#orgf32641b">6.3.1. Tanenbaum Solution</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org0e513ae">7. Address Spaces</a>
<ul>
<li><a href="#org0172bc2">7.1. Goals of Virtual Memory</a></li>
<li><a href="#orga719997">7.2. Types of Memory</a></li>
<li><a href="#org138a753">7.3. Address translation</a></li>
<li><a href="#orgf492603">7.4. 1950's <b>base and bounds</b> technique</a></li>
<li><a href="#org0a5fd88">7.5. Segmentation</a></li>
<li><a href="#orgfa38bcb">7.6. Sharing</a></li>
<li><a href="#org343617b">7.7. OS support</a></li>
</ul>
</li>
<li><a href="#org1417c45">8. Free Space Management</a>
<ul>
<li><a href="#org02b1fe7">8.1. Growing the Heap</a></li>
<li><a href="#orgb39eaca">8.2. Free Space Allocation Strategies</a>
<ul>
<li><a href="#orge0da8e3">8.2.1. Best fit</a></li>
<li><a href="#orgb9b8173">8.2.2. Worst fit</a></li>
<li><a href="#org109817a">8.2.3. Next Fit</a></li>
<li><a href="#orgcd50ae1">8.2.4. Segregated Lists</a></li>
<li><a href="#orgdeddb59">8.2.5. Buddy Allocation</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org4e13401">9. Paging</a>
<ul>
<li><a href="#org37d4a17">9.1. Address Translation</a></li>
<li><a href="#org7b07a63">9.2. Inside Page Tables</a></li>
<li><a href="#org8eedc9b">9.3. How Paging Works</a></li>
<li><a href="#org858ba2b">9.4. Speeding up Paging with TLBs</a>
<ul>
<li><a href="#orgef10e12">9.4.1. TLB Basic Algorithm</a></li>
<li><a href="#org4339cf9">9.4.2. Managing TLB Misses</a></li>
<li><a href="#org9bee52b">9.4.3. Handling Context Switches</a></li>
<li><a href="#org402333f">9.4.4. TLB Replacement Policies</a></li>
</ul>
</li>
<li><a href="#orgbb9caf0">9.5. Making Page Tables Smaller</a>
<ul>
<li><a href="#org79719f0">9.5.1. Bigger Pages</a></li>
<li><a href="#org998a735">9.5.2. Paging and Segments</a></li>
<li><a href="#org5f777b7">9.5.3. Multi-level Page Tables</a></li>
<li><a href="#org0c403b6">9.5.4. Inverted Page Tables</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org6d19621">10. Beyond Physical Memory</a>
<ul>
<li><a href="#orgd8c509f">10.1. Mechanisms</a>
<ul>
<li><a href="#org92ec8ac">10.1.1. Swap Space</a></li>
<li><a href="#org2a59ec4">10.1.2. The Present Bit</a></li>
<li><a href="#orgdf1951b">10.1.3. Page-replacement Policy</a></li>
<li><a href="#org87d6fd3">10.1.4. When Replacements Really Occur</a></li>
</ul>
</li>
<li><a href="#org5b66b61">10.2. Policies</a>
<ul>
<li><a href="#org15267d0">10.2.1. FIFO</a>
<ul>
<li><a href="#orgca62283">10.2.1.1. Belady's anomaly</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<p>
-<b>- mode: Org; org-download-image-dir: "./images/operating<sub>systems</sub>/"; -</b>-
</p>
<div id="outline-container-orge97fe1c" class="outline-2">
<h2 id="orge97fe1c"><span class="section-number-2">1</span> Operating System Key Concepts</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org326f8be" class="outline-3">
<h3 id="org326f8be"><span class="section-number-3">1.1</span> Motivation</h3>
<div class="outline-text-3" id="text-1-1">
<ol class="org-ol">
<li>Abstraction
<ul class="org-ul">
<li>Presents common high level functionality to users</li>
<li>Efficient and Portable</li>
</ul></li>
<li>Resource Allocator</li>
<li>Program Control
<ul class="org-ul">
<li>Monitor execution of program, and manage resource access privileges</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-org99974eb" class="outline-3">
<h3 id="org99974eb"><span class="section-number-3">1.2</span> Alarm signal</h3>
<div class="outline-text-3" id="text-1-2">
<p>
The alarm signal causes the operating system to suspend whatever it is
doing, save its registers on the stack, and start running a special
signal-handling procedure.
</p>
</div>
</div>
<div id="outline-container-orgc52533b" class="outline-3">
<h3 id="orgc52533b"><span class="section-number-3">1.3</span> Identification</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Each person authorized to use the OS is assigned a UID (User
Identification). Each process started has the UID of the person who
started it. The child process inherits the UID from the parent. Users
can also be members of groups, each with a GID (Group Identification).
</p>
</div>
</div>

<div id="outline-container-org2d01dce" class="outline-3">
<h3 id="org2d01dce"><span class="section-number-3">1.4</span> File systems</h3>
<div class="outline-text-3" id="text-1-4">
<p>
Before a file can be read or written, it must be opened, at which time
the permissions are checked. If access is permitted, the system
returns a small integer called the <b>file descriptor</b> to use in
subsequent operations.
</p>

<p>
<b>Special files</b> are provided in order tomake I/O devices look like
files. That way, they can be read and written using the same system
calls as are used for reading and writing files. <b>block special files</b>
are used to model devices that consist of a collection of randomly
addressable blocks, such as disks. A program can open a block special
file, and access a particular block to read it. <b>character special
files</b> are used to model printers, modems and other devices that
accept or output a character stream.
</p>
</div>
</div>

<div id="outline-container-orga1ebde5" class="outline-3">
<h3 id="orga1ebde5"><span class="section-number-3">1.5</span> Pipe</h3>
<div class="outline-text-3" id="text-1-5">
<p>
A sort of pseudofile that can be used to connect two processes. If
process A and B wish to talk using a pipe, they must set it up in
advance.
</p>


<div class="figure">
<p><img src="images/operating_systems/Operating%20Systems%20key%20Concepts/posix.png" alt="posix.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org185874f" class="outline-3">
<h3 id="org185874f"><span class="section-number-3">1.6</span> Process segments</h3>
<div class="outline-text-3" id="text-1-6">

<div class="figure">
<p><img src="images/operating_systems/process_segments.png" alt="process_segments.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgb4c62ae" class="outline-3">
<h3 id="orgb4c62ae"><span class="section-number-3">1.7</span> Files in UNIX</h3>
<div class="outline-text-3" id="text-1-7">
<p>
Every file in UNIX has a unique number, its i-number, that identifies
it. The i-number is an index into a table of <b>i-nodes</b>, one per file,
telling who owns the file, where its disk-blocks are and so one. A
directory is a file containing a set of (i-number, ASCII name) pairs.
</p>
</div>
</div>

<div id="outline-container-org5157deb" class="outline-3">
<h3 id="org5157deb"><span class="section-number-3">1.8</span> Hypervisors</h3>
<div class="outline-text-3" id="text-1-8">
<p>
In practice, the real distinction between a type 1 hypervisor and a
type 2 hypervisor is that a type 2 makes uses of a host operating
system and its file system to create processes, store files, and so
on. A type 1 hypervisor has no underlying sup- port and must perform
all these functions itself.
</p>
</div>
</div>
</div>

<div id="outline-container-org1b901ec" class="outline-2">
<h2 id="org1b901ec"><span class="section-number-2">2</span> Process</h2>
<div class="outline-text-2" id="text-2">
<p>
A program in execution. Associated with each process is a <b>address
space</b>. Address space is a list of memory locations from 0 to maximum
in which the program can write to.
</p>

<p>
Information about all the processes are stored in the operating system
table called the <b>process table</b>, which is an array structure, one for
each process currently in existence.
</p>

<p>
A suspended process consists of its address space, and its entry in
the process table, which contains the contents of the registers and
other items required to resume the process later on.
</p>
</div>
<div id="outline-container-org3115663" class="outline-3">
<h3 id="org3115663"><span class="section-number-3">2.1</span> Process Creation</h3>
<div class="outline-text-3" id="text-2-1">
<p>
OS needs to load its code and any static data (e.g. initialized
variables) into memory, into the address space of the process. Modern
OSes load these lazily, via the machinery of paging and swapping.
</p>

<ol class="org-ol">
<li>Run-time stack
<ul class="org-ul">
<li>Used for local variables, function parameters and return
addresses</li>
</ul></li>
<li>Heap
<ul class="org-ul">
<li>Dynamically allocated data, programs request this space by
calling <code>malloc()</code> and free it explicitly using <code>free()</code></li>
</ul></li>
<li>I/O related tasks
<ul class="org-ul">
<li>3 open file descriptors: <code>stdin</code>, <code>stdout</code> and <code>stderr</code></li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-org37ce3fd" class="outline-3">
<h3 id="org37ce3fd"><span class="section-number-3">2.2</span> Function Call</h3>
<div class="outline-text-3" id="text-2-2">
</div>
<div id="outline-container-org1dfd722" class="outline-4">
<h4 id="org1dfd722"><span class="section-number-4">2.2.1</span> Control Flow issues</h4>
<div class="outline-text-4" id="text-2-2-1">
<ol class="org-ol">
<li>Need to jump to the function body</li>
<li>Need to resume when the function call is done</li>
<li>Minimally, need to store the PC of the caller</li>
</ol>
</div>
</div>
<div id="outline-container-org42359a1" class="outline-4">
<h4 id="org42359a1"><span class="section-number-4">2.2.2</span> Data Storage issues</h4>
<div class="outline-text-4" id="text-2-2-2">
<ol class="org-ol">
<li>Need to pass parameters to the function</li>
<li>Need to capture the return result</li>
<li>May have local variable declarations</li>
</ol>
</div>
</div>
<div id="outline-container-orgfd7fc51" class="outline-4">
<h4 id="orgfd7fc51"><span class="section-number-4">2.2.3</span> Stack Memory</h4>
<div class="outline-text-4" id="text-2-2-3">
<p>
Define new region of memory, called <b>stack memory</b>, for function
invocations. A new hardware register, the <b>stack pointer</b>, stores
the current memory address of the top of the stack.
</p>

<p>
When the stack grows, the stack pointer decreases. The stack grows
from bottom up. This is true for most architectures.
</p>
</div>
</div>
<div id="outline-container-orge0acd05" class="outline-4">
<h4 id="orge0acd05"><span class="section-number-4">2.2.4</span> Stack Frame</h4>
<div class="outline-text-4" id="text-2-2-4">
<p>
The stack memory stores a bunch of stack frames, one stack frame for
each function invocation. The stack frame stores:
</p>

<ol class="org-ol">
<li>Local variables</li>
<li>Parameters</li>
<li>Return PC</li>
<li>Saved Registers</li>
<li>Saved Stack Pointer</li>
<li>Frame Pointer</li>
</ol>
</div>
</div>
<div id="outline-container-orgafd00d6" class="outline-4">
<h4 id="orgafd00d6"><span class="section-number-4">2.2.5</span> Function Call Convention (FCC)</h4>
<div class="outline-text-4" id="text-2-2-5">
<p>
There are different ways to setup stack frames. An example scheme is
described below.
</p>

<ol class="org-ol">
<li>Caller passes parameters with registers and/or stack</li>
<li>Caller saves return PC on stack</li>
<li><b>Transfer Control from Caller to Callee</b></li>
<li>Callee save registers used by callee. Save old SP and FP</li>
<li>Callee allocates space for local variables on stack</li>
<li>Callee updates stack pointer to top of stack</li>
</ol>

<p>
Teardown:
</p>

<ol class="org-ol">
<li>Callee: Restore saved registers, FP, SP</li>
<li><b>Transfer control from callee to caller using saved PC</b></li>
<li>Caller: Continues execution in caller</li>
</ol>
</div>
</div>

<div id="outline-container-org27d103d" class="outline-4">
<h4 id="org27d103d"><span class="section-number-4">2.2.6</span> Frame Pointer</h4>
<div class="outline-text-4" id="text-2-2-6">
<p>
Stack Pointer is hard to use as it can change. Frame pointer points to
a fixed location in a stack frame, and other items are accessed as
offsets from the frame pointer.
</p>
</div>
</div>
</div>
<div id="outline-container-org41b1455" class="outline-3">
<h3 id="org41b1455"><span class="section-number-3">2.3</span> Dynamic Memory Allocation</h3>
<div class="outline-text-3" id="text-2-3">
<p>
High Level Languages allow dynamic allocation of memory space, e.g.
C's <code>malloc</code>. These memory blocks have different behaviours. First,
they are only allocated at runtime, and hence cannot be placed in the
data region. Next, there is no definition deallocation timing, and
hence cannot be placed in the stack region.
</p>

<p>
Hence, a new region is needed, called the heap. Heap memory is a lot
trickier to manage. Variable size, and allocation/deallocation timing
is not known before hand.
</p>
</div>
</div>
<div id="outline-container-org7a1bae6" class="outline-3">
<h3 id="org7a1bae6"><span class="section-number-3">2.4</span> Process Identification</h3>
<div class="outline-text-3" id="text-2-4">
<p>
To distinguish processes from each other, a process ID (PID) is
assigned to each process.
</p>
</div>
</div>
<div id="outline-container-orgd7f2900" class="outline-3">
<h3 id="orgd7f2900"><span class="section-number-3">2.5</span> 5-state Process Model</h3>
<div class="outline-text-3" id="text-2-5">
<dl class="org-dl">
<dt>New</dt><dd>The process creation is started, but has not been
allocated the required resources.</dd>
<dt>Ready</dt><dd>Process is ready to run, but the OS has not chosen to run
it yet.</dd>
<dt>Running</dt><dd>A process is running if it is executing instructions on
the processor.</dd>
<dt>Blocked</dt><dd>Process has performed some kind of operation that
makes it not ready to run until another event has
taken place, e.g. being blocked by I/O.</dd>
<dt>Terminated</dt><dd>Process is finished, may require OS cleanup.</dd>
</dl>


<div class="figure">
<p><img src="images/operating_systems/process_lifecycle.png" alt="process_lifecycle.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org0cb829b" class="outline-3">
<h3 id="org0cb829b"><span class="section-number-3">2.6</span> Data structures required</h3>
<div class="outline-text-3" id="text-2-6">
<dl class="org-dl">
<dt>Process Table</dt><dd>keeps track of all processes</dd>
<dt>PCB</dt><dd>contains the entire execution context for a process</dd>
</dl>


<div class="figure">
<p><img src="images/operating_systems/process_ds.png" alt="process_ds.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org5cff88f" class="outline-3">
<h3 id="org5cff88f"><span class="section-number-3">2.7</span> Mechanism: Limited Direct Execution</h3>
<div class="outline-text-3" id="text-2-7">
<p>
The OS must virtualize the CPU in an efficient manner, while retaining
control over the system. To do so, both hardware and operating systems
support will be required. The OS will often use a judicious bit of
hardware support in order to accomplish its work effectively.
</p>
</div>
</div>
<div id="outline-container-org6001bec" class="outline-3">
<h3 id="org6001bec"><span class="section-number-3">2.8</span> Access Control</h3>
<div class="outline-text-3" id="text-2-8">
<p>
In <i>user mode</i>, applications do not have full access to hardware
resources. The OS runs in <i>kernel mode</i>, which has access to the full
resources of the machine.
</p>

<p>
Code can request access to system resource by calling the <i>trap</i> call,
which raises the privilege level to kernel mode. Once finished, the OS
calls the <i>return-from-trap</i> instruction, which returns the calling
user program, while reducing the privilege level back to user mode.
</p>

<p>
During bootup, the machine is started in kernel mode. The OS sets up a
trap table, and informs the hardware of the location of specialised
<i>trap handlers</i>, which is the code to run when certain exceptional
events occur. One such example is the hard-disk interrupt.
</p>
</div>
</div>
<div id="outline-container-org8f08f41" class="outline-3">
<h3 id="org8f08f41"><span class="section-number-3">2.9</span> General System Call Mechanism</h3>
<div class="outline-text-3" id="text-2-9">
<ol class="org-ol">
<li>User program invokes the library call, using the normal function
call mechanism</li>
<li>Library call places the <b>system call number</b> in a designated location</li>
<li>Library call executes a special instruction to switch from user
mode to kernel mode (known as TRAP)</li>
<li>Now in kernel mode, the appropriate system call handler is determined:
<ol class="org-ol">
<li>Using the system call number as index</li>
<li>This step is usually handled by a <b>dispatcher</b></li>
</ol></li>
<li>System call handler is executed</li>
<li>Control is returned to the library call, and switches from
kernel mode to user mode</li>
<li>Library call return to user program, via normal function
return mechanism</li>
</ol>
</div>
</div>

<div id="outline-container-orgdc46852" class="outline-3">
<h3 id="orgdc46852"><span class="section-number-3">2.10</span> Switching between processes</h3>
<div class="outline-text-3" id="text-2-10">
</div>
<div id="outline-container-orgb88a87d" class="outline-4">
<h4 id="orgb88a87d"><span class="section-number-4">2.10.1</span> Cooperative Approach</h4>
<div class="outline-text-4" id="text-2-10-1">
<p>
Processes transfer control of the CPU to the OS by making system
calls. The OS regains control of the CPU by waiting for a system call
or an illegal operation of some kind to take place.
</p>
</div>
</div>

<div id="outline-container-org16728aa" class="outline-4">
<h4 id="org16728aa"><span class="section-number-4">2.10.2</span> Non-cooperative Approach</h4>
<div class="outline-text-4" id="text-2-10-2">
<p>
The question is: what ca the OS do to ensure that a rogue process
does not take over the machine?
</p>

<p>
The answer is: <i>timer interrupt</i>. A timer device is programmed to
raise an interrupt at a fixed interval. Each time the interrupt is
raised, a pre-configured interrupt handler in the OS runs.
</p>

<p>
At this time, the OS will decide whether to continue running the
process, or switch to a different one. This is the role of the
<i>scheduler</i>.
</p>

<p>
If the decision is to switch processes, then the OS executes a
low-level piece of code which is referred to as the <i>context
switch</i>. The OS saves a few register values for the current
executing process. This includes:
</p>

<ol class="org-ol">
<li>Program Counter (PC)</li>
<li>Stack Pointer (Pointing to the new context)</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-orgbbfbc5a" class="outline-3">
<h3 id="orgbbfbc5a"><span class="section-number-3">2.11</span> Exception and Interrupts</h3>
<div class="outline-text-3" id="text-2-11">
<p>
Executing a machine level instruction can lead to exceptions, for
example arithmetic errors.
</p>

<p>
Exceptions are synchronous, and occur due to program execution. An
exception handle is executed automatically.
</p>

<p>
External events can interrupt the execution of a program. These are
usually hardware related: timer, keyboard events etc.
</p>

<p>
When an exception or an interrupt handler executes, control is
transferred to a handler routine automatically.
</p>

<p>
A handler does the following:
</p>

<ol class="org-ol">
<li>Save Register/CPU state</li>
<li>Perform Register/CPU</li>
<li>Restore Register/CPU</li>
<li>Return from interrupt</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org5bc59b6" class="outline-2">
<h2 id="org5bc59b6"><span class="section-number-2">3</span> Scheduling</h2>
<div class="outline-text-2" id="text-3">
<p>
Assumptions made:
</p>
<ol class="org-ol">
<li>Each job runs for the same amount of time</li>
<li>All jobs arrive at the same time</li>
<li>All jobs only use the CPU (i.e. they perform no I/O)</li>
<li>The run-time of each job is known</li>
</ol>
</div>

<div id="outline-container-orgeb44108" class="outline-3">
<h3 id="orgeb44108"><span class="section-number-3">3.1</span> Scheduling Metrics</h3>
<div class="outline-text-3" id="text-3-1">
<ol class="org-ol">
<li>Turn-around time</li>
</ol>
</div>
</div>

<div id="outline-container-org3c33b5a" class="outline-3">
<h3 id="org3c33b5a"><span class="section-number-3">3.2</span> First Come First Served (FCFS)</h3>
<div class="outline-text-3" id="text-3-2">
<p>
Example:
</p>
<ul class="org-ul">
<li>A, B and C arrived at time T=0.</li>
<li>A runs first, followed by B, then C</li>
</ul>
<p>
Average Turnaround time:
(10 + 20 + 30)/3 = 20
</p>
</div>
<div id="outline-container-orgd92c11e" class="outline-4">
<h4 id="orgd92c11e"><span class="section-number-4">3.2.1</span> Pros</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
Easy to implement
</p>
</div>
</div>
<div id="outline-container-org74b5b1a" class="outline-4">
<h4 id="org74b5b1a"><span class="section-number-4">3.2.2</span> Cons</h4>
<div class="outline-text-4" id="text-3-2-2">
<p>
<i>Convoy effect</i>: a number of relatively-short potential consumers
of a resource get queued behind a heavyweight resource consumer.
</p>
<ul class="org-ul">
<li>E.g. A takes 100 TU, B and C 10</li>
<li>Average turnaround time: (100 + 110 + 120)/3</li>
<li>if instead, B and C were scheduled before A, it would be (10 + 20+
120)/3</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orge91f610" class="outline-3">
<h3 id="orge91f610"><span class="section-number-3">3.3</span> Shortest Job First (SJF)</h3>
<div class="outline-text-3" id="text-3-3">
<p>
Schedule the job that takes the shortest TU.
</p>
</div>
<div id="outline-container-org76b749f" class="outline-4">
<h4 id="org76b749f"><span class="section-number-4">3.3.1</span> Pros</h4>
<div class="outline-text-4" id="text-3-3-1">
<p>
Optimizes for Turnaround time
</p>
</div>
</div>
<div id="outline-container-orgdfd533f" class="outline-4">
<h4 id="orgdfd533f"><span class="section-number-4">3.3.2</span> Cons</h4>
<div class="outline-text-4" id="text-3-3-2">
<p>
Relies on unrealistic assumptions. For example, if A takes 100TU, and
B and C takes 10 TU, but B and C arrive only shortly after A, then A
will still get queued, and the turnaround time will be high (convoy
problem again)
</p>
</div>
</div>
</div>
<div id="outline-container-org5386958" class="outline-3">
<h3 id="org5386958"><span class="section-number-3">3.4</span> Shortest Time-to-Completion First (SRT)</h3>
<div class="outline-text-3" id="text-3-4">
<p>
Any time a new job enters the system, it determines the job that has
the least time left, and schedules that one first.
</p>
</div>
<div id="outline-container-org008004e" class="outline-4">
<h4 id="org008004e"><span class="section-number-4">3.4.1</span> Pros</h4>
<div class="outline-text-4" id="text-3-4-1">
<p>
Good turnaround time
</p>
</div>
</div>
<div id="outline-container-org3b29230" class="outline-4">
<h4 id="org3b29230"><span class="section-number-4">3.4.2</span> Cons</h4>
<div class="outline-text-4" id="text-3-4-2">
<p>
Bad for response time and interactivity.
</p>
</div>
</div>
</div>
<div id="outline-container-org54533f3" class="outline-3">
<h3 id="org54533f3"><span class="section-number-3">3.5</span> Round Robin</h3>
<div class="outline-text-3" id="text-3-5">
<p>
Instead of running jobs to completion, RR runs a job for a <i>time
slice</i>, also sometimes called a <i>scheduling quantum</i>. After the time
slice, the next job in the run queue is scheduled. The length of the
time slice must be a multiple of the length of the timer-interrupt
period.
</p>

<p>
The shorter the time slice, the better the performance of RR under the
response-time metric. However, if the time slice is too short, there
will be a lot of overhead, and the cost of context switching will
dominate the overall performance.
</p>
</div>
<div id="outline-container-org2af9825" class="outline-4">
<h4 id="org2af9825"><span class="section-number-4">3.5.1</span> Incorporating I/O</h4>
<div class="outline-text-4" id="text-3-5-1">
<p>
By treating each CPU burst as a job, the scheduler makes sure
processes that are "interactive" get run frequently.
</p>
</div>
</div>
</div>

<div id="outline-container-org15c9010" class="outline-3">
<h3 id="org15c9010"><span class="section-number-3">3.6</span> Multi-level Feedback Queue (MLFQ)</h3>
<div class="outline-text-3" id="text-3-6">
<ol class="org-ol">
<li>Optimise <i>turnaround time</i>.</li>
<li>Make the system responsive to interactive users, minimise <i>response
time</i>.</li>
</ol>

<p>
How to schedule without perfect knowledge? (Knowing the length of the
job). Many jobs have phases of behaviour, and are thus predictable.
</p>

<p>
MLFQ has a number of distinct queues, each assigned a different
<i>priority level</i>. At any given time, a job that is ready to run is on
a single queue.
</p>

<ul class="org-ul">
<li>Rule 1: If Priority(A) &gt; Priority(B), A runs</li>
<li>Rule 2: If Priority(A) = Priority(B), A and B run in RR</li>
</ul>

<p>
Note that job priority <i>changes</i> over time.
</p>

<p>
First try at MLFQ:
</p>
<ul class="org-ul">
<li>Rule 3: When a job enters the system, it is placed at the highest
priority (the top most queue)</li>
<li>Rule 4a: If a job uses up an entire time slice while running, its
priority is <i>reduced</i> (it moves down one queue)</li>
<li>Rule 4b: If a job gives up the CPU before the time slice is up, it
stays at the same <i>priority</i> level.</li>
</ul>

<p>
Problems:
</p>
<ol class="org-ol">
<li><i>starvation</i>: if there are "too many" interactive jobs in the
system, they will combine to consume <i>all</i> CPU time, and
long-running jobs will never receive any CPU time.</li>
<li><i>Gaming the scheduler</i>: One can stop using the CPU right before the
time slice ends, then it will maintain at top priority.</li>
</ol>

<p>
Attempt 2:
</p>
<ul class="org-ul">
<li>Rule 5: After some time period S, move all the jobs in the system to
the topmost queue</li>
</ul>

<p>
This solves two problems:
</p>
<ol class="org-ol">
<li>Processes are guaranteed not to starve: by sitting in the top
queue, a job will share the CPU with other high-priority jobs in a
round-robin fashion, and will eventually receive service</li>
<li>If a CPU-bound job has become interactive, the scheduler treats it
properly once it has received the priority boost</li>
</ol>

<p>
Attempt 3:
Instead of forgetting how much of a time slice a process used at a
given level, the scheduler should keep track, once a process has used
its allotment, it is demoted to the next priority queue.
</p>

<ul class="org-ul">
<li>Rule 4: Once a job uses up its time allotment at a given level
(regardless of how many times it has given up the CPU), its priority
is reduced</li>
</ul>
</div>

<div id="outline-container-orgfa6ee25" class="outline-4">
<h4 id="orgfa6ee25"><span class="section-number-4">3.6.1</span> Tuning MLFQ</h4>
<div class="outline-text-4" id="text-3-6-1">
<ol class="org-ol">
<li>Varying time-slice length across different queues. Shorter time
slices are comprised of interactive jobs, and quickly alternating
between them makes sense</li>
<li>The low-priority queues are CPU bound, and longer time slices work well.</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-orgc03da43" class="outline-3">
<h3 id="orgc03da43"><span class="section-number-3">3.7</span> Lottery Scheduling</h3>
<div class="outline-text-3" id="text-3-7">
<p>
Tickets are used to represent the share of a resource that a process
should receive. Lottery scheduling achieves probabilistic fair sharing
of the CPU resources.
</p>
</div>
</div>
</div>

<div id="outline-container-orgcdeb605" class="outline-2">
<h2 id="orgcdeb605"><span class="section-number-2">4</span> Concurrency</h2>
<div class="outline-text-2" id="text-4">
<p>
Processes take a single physical CPU and turn it into multiple virtual
CPUs, enabling the illusion of multiple programs running at the same
time.
</p>

<p>
Now, we will examine the abstraction for running a single process:
that of a thread.
</p>
</div>
</div>
<div id="outline-container-org4403a85" class="outline-2">
<h2 id="org4403a85"><span class="section-number-2">5</span> Thread</h2>
<div class="outline-text-2" id="text-5">
<p>
The state of a single thread is similar to that of a process. It has a
program counter (PC) that tracks where the program is fetching
instructions from. Each thread has its own private set of registers it
uses for computation. If 2 threads are running on a single processor,
switching from a running one (T1) to running the other (T2) requires a
<i>context switch</i>. <i>Thread Control Blocks</i> (TCBs) store the state of
each thread of a process. Unlike the context switch for processes, the
address space for threads remain the same.
<img src="images/operating_systems/thread_add_space.png" alt="thread_add_space.png" />
</p>
</div>

<div id="outline-container-org5966dc7" class="outline-3">
<h3 id="org5966dc7"><span class="section-number-3">5.1</span> Example Thread creation</h3>
<div class="outline-text-3" id="text-5-1">
<div class="org-src-container">
<pre class="src src-c">#include &lt;stdio.h&gt;
#include &lt;assert.h&gt;
#include &lt;pthread.h&gt;

void *mythread(void *arg) {
  printf("%s\n", (char *) arg);
  return NULL; 
}

int main (int argc, char* argv[]) {
  pthread_t p1, p2;
  br int rc;
  printf("main: begin\n");
  rc = pthread_create(&amp;p1, NULL, mythread, "A"); assert(rc == 0);
  rc = pthread_create(&amp;p2, NULL, mythread, "B"); assert(rc == 0);
  //join waits for the threads to finish
  rc = pthread_join(p1, NULL); assert (rc == 0);
  rc = pthread_join(p2, NULL); assert (rc == 0);
  printf("main: end");
  return 0;
}
</pre>
</div>
</div>
</div>

<div id="outline-container-org8a57f37" class="outline-3">
<h3 id="org8a57f37"><span class="section-number-3">5.2</span> Issues with Uncontrolled Scheduling</h3>
<div class="outline-text-3" id="text-5-2">
</div>
<div id="outline-container-org8eb67c8" class="outline-4">
<h4 id="org8eb67c8"><span class="section-number-4">5.2.1</span> Race Condition</h4>
<div class="outline-text-4" id="text-5-2-1">
<p>
Context switches that occur at untimely points in the execution can
result in the wrong result. Because multiple threads executing this
code can result in a race condition, we call this code a <i>critical
section</i>. What's required for this code to run properly is <i>mutual
exclusion</i>. This property guarantees that if one thread is executing
within the critical section, others will be prevented from doing so.
</p>
</div>
</div>
<div id="outline-container-org25851c7" class="outline-4">
<h4 id="org25851c7"><span class="section-number-4">5.2.2</span> Key Terms</h4>
<div class="outline-text-4" id="text-5-2-2">
<dl class="org-dl">
<dt>Critical Section</dt><dd>piece of code that accesses a <i>shared</i> resource,
usually a variable or data structure</dd>
<dt>Race Condition</dt><dd>A situation which arises if multiple threads of
execution enter the critical section at roughly
the same time; both attempt to update the shared
data structure at the same time, leading to
surprising and sometimes undesirable outcomes</dd>
<dt>Indeterminate Program</dt><dd>Consists of one or more race conditions;
the output is non deterministic, something typically expected of
computer programs</dd>
<dt>Mutual Exclusion</dt><dd>threads use <i>mutual exclusion</i> primitives to
avoid the problems that concurrency yields, such as race conditions</dd>
</dl>
</div>
</div>
<div id="outline-container-org1db2fcb" class="outline-4">
<h4 id="org1db2fcb"><span class="section-number-4">5.2.3</span> The wish for atomicity</h4>
<div class="outline-text-4" id="text-5-2-3">
<p>
What if we had a super-instruction like this:
</p>

<div class="org-src-container">
<pre class="src src-text">memory-add 0x8044a1c, $0x1
</pre>
</div>

<p>
Assume this instruction adds a value to a memory location, and the
hardware guarantees that it executes atomically. This would be easy if
the instruction set contained only 1 instruction. However, in the
general case this is not possible.
</p>

<p>
Instead, we ask the hardware for a few useful instructions upon which
we can build a general set of what is called <i>synchronisation
primitives</i>.
</p>
</div>
</div>
</div>
<div id="outline-container-orgbd56ead" class="outline-3">
<h3 id="orgbd56ead"><span class="section-number-3">5.3</span> Thread API</h3>
<div class="outline-text-3" id="text-5-3">
<div class="org-src-container">
<pre class="src src-c">#include &lt;pthread.h&gt;

int pthread_create (pthread_t * thread,
                    const pthread_attr_t* attr,
                    void * (*start_routine) (void *)
                    void * arg);
</pre>
</div>

<ol class="org-ol">
<li><code>thread</code> is a pointer to the structure of type <code>pthread_t</code>, used to
interact with the thread</li>
<li><code>attr</code> is used to specify attributes this thread might have,
including setting the stack size, and scheduling priority of the
thread. We can usually pass NULL in.</li>
<li><code>start_routine</code> is the function this thread should start running in</li>
<li><code>arg</code> is the argument <code>start_routine</code> requires.</li>
</ol>

<div class="org-src-container">
<pre class="src src-c">int pthread_join(pthread_t trhead, void ** value_ptr);
</pre>
</div>

<p>
<code>pthread_join</code> waits for the thread's completion.
</p>
</div>
<div id="outline-container-orgf667ce8" class="outline-4">
<h4 id="orgf667ce8"><span class="section-number-4">5.3.1</span> Locks API</h4>
<div class="outline-text-4" id="text-5-3-1">
<div class="org-src-container">
<pre class="src src-c">int pthread_mutex_lock(pthread_mutex_t *mutex);
int pthread_mutex_unlock(pthread_mutex_t *mutex);

// Usage
//sets the lock to default values, making the lock usable
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;

// dynamic way to do it is to make a call:
int rc = pthread_mutex_init(&amp;lock, NULL);
assert (rc == 0); //always check success!

pthread_mutex_lock(&amp;lock);
// Critical section
x = x + 1;
pthread_mutex_unlock(&amp;lock);
</pre>
</div>

<div class="org-src-container">
<pre class="src src-c">int pthread_mutex_trylock(pthread_mutex_t *mutex);
int pthread_mutex_timedlock(pthread_mutex_t *mutex,
                            struct timespec *abs_timeout);
</pre>
</div>

<p>
These two calls are used in lock acquisition. <code>trylock</code> returns
failure if the lock is already held, and <code>timedlock</code> returns after a
timeout or after acquiring the lock, whichever happens first.
</p>
</div>
</div>
<div id="outline-container-org9871092" class="outline-4">
<h4 id="org9871092"><span class="section-number-4">5.3.2</span> Condition Variables</h4>
<div class="outline-text-4" id="text-5-3-2">
<div class="org-src-container">
<pre class="src src-c">int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);
int pthread_cond_signal(pthread_cond_t *cond);
</pre>
</div>

<p>
<b>condition variables</b> are useful when some kind of signalling must
 take place between threads.
</p>

<div class="org-src-container">
<pre class="src src-c">pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t init = PTHREAD_COND_INITIALIZER;

int rc = pthread_mutex_lock(&amp;lock); assert(rc == 0);
while (initialized == 0) {
  int rc = pthread_cond_wait(&amp;init, &amp;lock);
  assert (rc == 0);
}
pthread_mutex_unlock(&amp;lock);

//Some other thread
pthread_mutex_lock(&amp;lock);
initialized = 1;
pthread_cond_signal(&amp;init);
pthread_mutex_unlock(&amp;lock);
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org5f3e9f8" class="outline-3">
<h3 id="org5f3e9f8"><span class="section-number-3">5.4</span> Properties of Correct CS Implementation</h3>
<div class="outline-text-3" id="text-5-4">
<dl class="org-dl">
<dt>Mutual Exclusion</dt><dd>If process P1 is executing in critical section,
all other processes are prevented from entering the critical section</dd>
<dt>Progress</dt><dd>If no process is in a critical section, one of the
waiting processes should be granted access</dd>
<dt>Bounded Wait</dt><dd>After process p1 request to enter critical section,
there exists an upperbound of number of times other
processes can enter the critical section before p1</dd>
<dt>Independence</dt><dd>Process <b>not</b> executing in critical section should
never block other process</dd>
</dl>
</div>
</div>
<div id="outline-container-orgc92dd40" class="outline-3">
<h3 id="orgc92dd40"><span class="section-number-3">5.5</span> Locks</h3>
<div class="outline-text-3" id="text-5-5">
<p>
Calling the routine <code>lock()</code> tries to acquire the lock; if no other
thread holds the lock, the thread will acquire the lock and enter the
critical section; this thread is sometimes said to be the <b>owner</b> of
the lock.Once the <b>owner</b> of the lock calls <code>unlock()</code>, the lock in
now available again. If no othre threads are waiting for the lock
(i.e. no other thread has called <code>lock()</code> and is stuck), the state of
the lock is simply changed to free, if thee are waiting threads, one
of them will acquire the lock.
</p>
</div>
<div id="outline-container-org529562a" class="outline-4">
<h4 id="org529562a"><span class="section-number-4">5.5.1</span> Pthread Locks</h4>
<div class="outline-text-4" id="text-5-5-1">
<p>
The name that the POSIX library uses for a lock is a <b>mutex</b>, as it is
used to provide <b>mutual exclusion</b> between threads. Different locks
can be initialized to protect different critical sections.
</p>
</div>
</div>
<div id="outline-container-orge41ed99" class="outline-4">
<h4 id="orge41ed99"><span class="section-number-4">5.5.2</span> Evaluating locks</h4>
<div class="outline-text-4" id="text-5-5-2">
<dl class="org-dl">
<dt>mutual exclusion</dt><dd>does the lock work, preventing multiple threads
from entering a critical section?</dd>
<dt>fairness</dt><dd>Does each thread contending for the lock get a fair shot?</dd>
<dt>performance</dt><dd>Are the time overheads added by using the lock significant?</dd>
</dl>
</div>
</div>
<div id="outline-container-orgab70f97" class="outline-4">
<h4 id="orgab70f97"><span class="section-number-4">5.5.3</span> Approach 1: Controlling Interrupts</h4>
<div class="outline-text-4" id="text-5-5-3">
<p>
Using a special hardware instruction, turn off all interrupts during
critical section:
</p>

<div class="org-src-container">
<pre class="src src-c">void lock() {
  DisableInterrupts(); 
}

void unlock() {
  EnableInterrupts();
}
</pre>
</div>
</div>
<div id="outline-container-orgd49da64" class="outline-5">
<h5 id="orgd49da64"><span class="section-number-5">5.5.3.1</span> Pros</h5>
<div class="outline-text-5" id="text-5-5-3-1">
<ol class="org-ol">
<li>Simplicity</li>
</ol>
</div>
</div>
<div id="outline-container-org59fb683" class="outline-5">
<h5 id="org59fb683"><span class="section-number-5">5.5.3.2</span> Cons</h5>
<div class="outline-text-5" id="text-5-5-3-2">
<ol class="org-ol">
<li>Requires calling thread to perform a <i>privileged</i> operation</li>
<li>Doesn't work on multiprocessor systems</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org37061f4" class="outline-4">
<h4 id="org37061f4"><span class="section-number-4">5.5.4</span> Approach 2: Test and Set</h4>
<div class="outline-text-4" id="text-5-5-4">
<p>
Hardware support for atomicity was created. This is known as the
<b>test-and-set instruction</b>, or <b>atomic exchange</b>.
</p>

<p>
The idea is to use a variable to indicate whether some thread has
possession of a lock. Calling <code>lock()</code> then tests and sets that variable.
</p>

<p>
However, this presents several issues:
</p>
<ol class="org-ol">
<li><b>No Mutex</b>!</li>
<li>The thread waiting to acquire a lock is endlessly checking for the
value of flag, a technique known as <b>spin-waiting</b>, which wastes
time waiting for another thread to release a lock.</li>
</ol>

<p>
With hardware support for <b>test-and-set</b>, we achieve mutex, and have a
<b>spin lock</b>! To work correctly on a single processor, it requires a
preemptive scheduler, one that will interrupt a thread via  atimer, in
order to run a different thread, from time to time.
</p>
</div>
<div id="outline-container-org15a019c" class="outline-5">
<h5 id="org15a019c"><span class="section-number-5">5.5.4.1</span> Evaluating the spin lock:</h5>
<div class="outline-text-5" id="text-5-5-4-1">
<dl class="org-dl">
<dt>correctness</dt><dd>YES</dd>
<dt>fairness</dt><dd>NO, a thread may spin forever under contention</dd>
<dt>performance</dt><dd>NO, high performance overheads</dd>
</dl>

<p>
Other hardware primitives one can use to write locks:
</p>
<ol class="org-ol">
<li>LoadLinked and StoreConditional</li>
<li>Fetch-And-Add (ticket lock)</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org187258a" class="outline-4">
<h4 id="org187258a"><span class="section-number-4">5.5.5</span> Two Phase Locks</h4>
<div class="outline-text-4" id="text-5-5-5">
<p>
A two-phase lock realises that spinning can be useful, particularly if
the lock is about to be released. In the first-phase, the lock spins
for a while, hoping that it can acquire a lock. However, if the lock
is not acquired during the first phase, the second phase is entered,
where the caller is put to sleep, and only woken up when the lock
becomes free later.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org58ce580" class="outline-2">
<h2 id="org58ce580"><span class="section-number-2">6</span> Classical Synchronization Problems</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org036135b" class="outline-3">
<h3 id="org036135b"><span class="section-number-3">6.1</span> Producer/Consumer</h3>
<div class="outline-text-3" id="text-6-1">
<p>
Producers and Consumers share a bounded buffer K
</p>

<p>
Blocking Version contains 3 semaphores:
</p>
<ol class="org-ol">
<li>Binary semaphore (initialized to 1) [mutex]</li>
<li>!Full (initialized to 4) [!Full]</li>
<li>!Empty (initialized to 0) [!Empty]</li>
</ol>

<div class="org-src-container">
<pre class="src src-c">//Producer
while (TRUE) {
  Produce Item;
  wait(notFull);
  wait(mutex);
  buffer[in] = item;
  in = (in + 1) % K;
  count++;
  signal(mutex);
  signal(notEmpty);
 }

// Consumer
while (TRUE) {
  wait(notEmpty);
  wait(mutex);
  item = buffer[out];
  out = (out + 1) % K;
  count--;
  signal(mutex);
  signal(notFull);
  Consume Item;
}

</pre>
</div>
</div>
</div>
<div id="outline-container-orgbba733c" class="outline-3">
<h3 id="orgbba733c"><span class="section-number-3">6.2</span> Readers/Writers</h3>
<div class="outline-text-3" id="text-6-2">
<p>
Processes share a data structure D
</p>
<ol class="org-ol">
<li>Reader: Retrieves information from D</li>
<li>Writer: Modifies information from D</li>
<li>Writer must have exclusive access</li>
<li>Readers can read with other readers</li>
</ol>

<div class="org-src-container">
<pre class="src src-c">while (true) {
  wait(roomEmpty);
  //Modifies data;
  signal(roomEmpty);
}

while (true) {
  wait(mutex);
  nReader++;
  if (nReader == 1) {
    wait(roomEmpty);
  }
  signal(mutex);

  // Reads data;
  wait(mutex);
  nReader --;
  if (nReader == 0) {
    signal(roomEmpty);
  }
  signal(mutex);
}
</pre>
</div>
</div>
</div>
<div id="outline-container-org0b02dae" class="outline-3">
<h3 id="org0b02dae"><span class="section-number-3">6.3</span> Dining Philosophers</h3>
<div class="outline-text-3" id="text-6-3">
<p>
Philosophers sitting in a circle, requiring resource from both left
and right side.
</p>
</div>
<div id="outline-container-orgf32641b" class="outline-4">
<h4 id="orgf32641b"><span class="section-number-4">6.3.1</span> Tanenbaum Solution</h4>
<div class="outline-text-4" id="text-6-3-1">
<div class="org-src-container">
<pre class="src src-C">#define N 5
#define LEFT i
#define RIGHT ((i+1)%N)
#define THINKING 1
#define HUNGRY 1
#define EATING 2

int state[N];

void philosopher(int i) {
  while(true) {
    think(); 
    hungry();
    takeChpStcks(i);
    eat();
    putChpStcks(i);
  }
}
void takeChpStcks(i) {
  wait(mutex);
  state[i] = HUNGRY;
  safeToEat(i);
  signal(mutex);
  wait(s[i]);
}

void safeToEat(i) {
  if (state[i] == HUNGRY &amp;&amp;
      state[LEFT] !=EATING &amp;&amp;
      state[RIGHT] != EATING) {
    state[i] = EATING;
    signal(s[i]);
  }
}

void putChpStcks(i) {
  wait(mutex);
  state[i] = THINKING;
  safeToEat(LEFT);
  safeToEat(RIGHT);
  signal(mutex);
}
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-org0e513ae" class="outline-2">
<h2 id="org0e513ae"><span class="section-number-2">7</span> Address Spaces</h2>
<div class="outline-text-2" id="text-7">
<p>
While saving and storing register-level state is relatively fast,
saving the entire contents of memory to disk is non-performant. We'd
rather leave processes in memory while switching between them,
allowing the OS to implement time sharing efficiently.
</p>

<p>
The OS will need to create an <b>easy to use</b> abstraction of physical
memory. This abstraction is called the <i>address space</i>.
</p>
</div>
<div id="outline-container-org0172bc2" class="outline-3">
<h3 id="org0172bc2"><span class="section-number-3">7.1</span> Goals of Virtual Memory</h3>
<div class="outline-text-3" id="text-7-1">
<dl class="org-dl">
<dt>transparency</dt><dd>invisible to the running program, and the program
behaves as if it has its own private virtual memory</dd>
<dt>efficiency</dt><dd>time and space efficient, via hardware support such
as TLBs.</dd>
<dt>protection</dt><dd>protects processes from one another, delivering the
property of <b>isolation</b> among processes.</dd>
</dl>
</div>
</div>
<div id="outline-container-orga719997" class="outline-3">
<h3 id="orga719997"><span class="section-number-3">7.2</span> Types of Memory</h3>
<div class="outline-text-3" id="text-7-2">
<dl class="org-dl">
<dt>stack memory</dt><dd>allocations and de-allocations are handled
implicitly by the compiler</dd>
<dt>heap memory</dt><dd>allocations and de-allocations are explicitly
handled by programmer</dd>
</dl>
</div>
</div>
<div id="outline-container-org138a753" class="outline-3">
<h3 id="org138a753"><span class="section-number-3">7.3</span> Address translation</h3>
<div class="outline-text-3" id="text-7-3">
<p>
The hardware transforms each memory access, changing the virtual
address provided by the instruction to a physical address where the
desired information is actually located.
</p>
</div>
</div>
<div id="outline-container-orgf492603" class="outline-3">
<h3 id="orgf492603"><span class="section-number-3">7.4</span> 1950's <b>base and bounds</b> technique</h3>
<div class="outline-text-3" id="text-7-4">
<p>
2 hardware registers in each CPU: the <i>base register</i>, and the <i>bounds
register</i>. This pair allows the placement of address space anywhere in
physical memory, and do so while ensuring that the process can only
access its own address space.
</p>

<p>
The OS decides where in physical memory it should be loaded, and sets
the base register to that value. 
</p>

<p>
Any memory reference generated by the process is translated:
</p>

<p>
\( physical address = virtual address + base \)
</p>

<p>
Because this translation is done at runtime, this technique is also
known as <b>dynamic relocation</b>.
</p>

<ol class="org-ol">
<li>The OS must take action when a process is created, searching a data
structure to find room for the new address space and then mark it used.</li>
<li>The OS must take action when a process is terminated, reclaiming
all of the memory is use.</li>
<li>OS must take action when a context switch occurs. This is because
there is <i>only one base and bounds register</i>, and their values
differ for each running program.</li>
<li>Access to the base and bounds register is privileged, and special
hardware instructions are required.</li>
</ol>

<p>
Dynamic relocation is inefficient. If the space inside the allocated
unit is not all used, it is wasted, and this is called <b>internal
fragmentation</b>. 
</p>
</div>
</div>
<div id="outline-container-org0a5fd88" class="outline-3">
<h3 id="org0a5fd88"><span class="section-number-3">7.5</span> Segmentation</h3>
<div class="outline-text-3" id="text-7-5">
<p>
A segment is a contiguous portion of the address space of a particular
length. We have 3 logically-different segments: code, stack and heap.
The OS can place each of these segments in different parts of physical
memory, and avoid filling physical memory with unused virtual address
space.
</p>

<p>
To support segmentation of this form, the Memory Management Unit (MMU)
has, instead of one, 3 base and bounds register pairs
</p>

<p>
When an illegal address is accessed, the hardware detects that the
address is out of bounds, and the OS terminates the offending process
with a segmentation fault.
</p>

<p>
To figure out which segment to use, bits in the virtual address are
often reserved. This is the virtual address 4200 in binary form:
</p>


<div class="figure">
<p><img src="images/operating_systems/Address Spaces/screenshot_2017-11-04_20-51-42.png" alt="screenshot_2017-11-04_20-51-42.png" />
</p>
</div>

<p>
The hardware would need to know how the segments grow to translate
virtual address differently. In the case of the stack, a negative
offset is added to the base to calculate the correct physical address.
</p>
</div>
</div>
<div id="outline-container-orgfa38bcb" class="outline-3">
<h3 id="orgfa38bcb"><span class="section-number-3">7.6</span> Sharing</h3>
<div class="outline-text-3" id="text-7-6">
<p>
To save memory, it useful to share certain memory segments, like
the code segment.
</p>

<p>
To support sharing in a safe way, <b>protection bits</b> are added per
segment, indicating whether or not a program can read or write to a
segment.
</p>


<div class="figure">
<p><img src="images/operating_systems/Address Spaces/screenshot_2017-11-04_20-57-25.png" alt="screenshot_2017-11-04_20-57-25.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org343617b" class="outline-3">
<h3 id="org343617b"><span class="section-number-3">7.7</span> OS support</h3>
<div class="outline-text-3" id="text-7-7">
<p>
Physical memory quickly becomes full of little holes of free space,
making it difficult to allocate to new segments, or grow existing
ones. This is <b>external fragmentation</b>.
</p>

<p>
One solution is to <b>compact</b> physical memory by rearranging the
existing segments. However, compaction is expensive as copying
segments is memory intensive and require processor time.
</p>

<p>
One approach is to use a free-list management algorithm that tries to
keep large extents of memory for allocation. Algorithms include:
</p>

<ol class="org-ol">
<li>Best-fit</li>
<li>Worst-fit</li>
<li>First-fit</li>
<li>Buddy System</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org1417c45" class="outline-2">
<h2 id="org1417c45"><span class="section-number-2">8</span> Free Space Management</h2>
<div class="outline-text-2" id="text-8">
<p>
A free list contains a set of elements that describe the free space
still remaining in the heap. To track the size of allocated regions,
the header contains the size of the allocated region.
</p>

<div class="org-src-container">
<pre class="src src-c">typedef struct __header_t {
  int size;
  int magic;
}
</pre>
</div>
</div>
<div id="outline-container-org02b1fe7" class="outline-3">
<h3 id="org02b1fe7"><span class="section-number-3">8.1</span> Growing the Heap</h3>
<div class="outline-text-3" id="text-8-1">
<p>
Traditional allocators start of with a small heap. When more memory is
required, the <code>sbrk</code> system call is made to request for more memory.
The OS finds free physical pages, maps them to the address space of
the requesting process, and returns the value of the end of the new heap.
</p>
</div>
</div>
<div id="outline-container-orgb39eaca" class="outline-3">
<h3 id="orgb39eaca"><span class="section-number-3">8.2</span> Free Space Allocation Strategies</h3>
<div class="outline-text-3" id="text-8-2">
</div>
<div id="outline-container-orge0da8e3" class="outline-4">
<h4 id="orge0da8e3"><span class="section-number-4">8.2.1</span> Best fit</h4>
<div class="outline-text-4" id="text-8-2-1">
<ol class="org-ol">
<li>Search the free list and find chunks of free memory that are as big
or bigger than the requested size</li>
<li>Return the smallest chunk</li>
</ol>

<p>
Naive implementations are slow because of the exhaustive search
required to find the correct free block.
</p>
</div>
</div>
<div id="outline-container-orgb9b8173" class="outline-4">
<h4 id="orgb9b8173"><span class="section-number-4">8.2.2</span> Worst fit</h4>
<div class="outline-text-4" id="text-8-2-2">
<ol class="org-ol">
<li>Find the largest chunk</li>
<li>Return the requested size, keeping the remaining chunk on the free
list</li>
</ol>

<p>
Exhaustive search is also required to determine the largest chunk, and
studies have shown this still leads to excess fragmentation.
</p>
</div>
</div>
<div id="outline-container-org109817a" class="outline-4">
<h4 id="org109817a"><span class="section-number-4">8.2.3</span> Next Fit</h4>
<div class="outline-text-4" id="text-8-2-3">
<ol class="org-ol">
<li>Keep an extra pointer to the location within the list where one was
looking last</li>
<li>Spread searches for free space throughout the list more uniformly</li>
</ol>

<p>
Performance similar to first fit.
</p>
</div>
</div>
<div id="outline-container-orgcd50ae1" class="outline-4">
<h4 id="orgcd50ae1"><span class="section-number-4">8.2.4</span> Segregated Lists</h4>
<div class="outline-text-4" id="text-8-2-4">
<p>
If a particular application has one (or a few) popular-size requests
that it makes, keep a separate list just to manage objects of that
size; all other requests are forwarded to a more general memory
allocator.
</p>

<p>
When the kernel boots up, it allocates a number of <b>object caches</b> for
kernel objects that are likely to be requested frequently.
</p>
</div>
</div>
<div id="outline-container-orgdeddb59" class="outline-4">
<h4 id="orgdeddb59"><span class="section-number-4">8.2.5</span> Buddy Allocation</h4>
<div class="outline-text-4" id="text-8-2-5">
<p>
Free memory is conceptually thought of as one big space of size
\(2^N\).
</p>

<p>
When a request is made, search for free space recursively divides free
space into 2 until a block big enough to accommodate the result is
found. 
</p>

<p>
Here is an example of a 64KB free space getting divided in the search
for a 7KB block:
</p>


<div class="figure">
<p><img src="images/operating_systems/Free Space Management/screenshot_2017-11-05_16-27-35.png" alt="screenshot_2017-11-05_16-27-35.png" />
</p>
</div>

<p>
This scheme can suffer from <b>internal fragmentation</b>. Upon freeing a
block, the allocator checks its buddy and sees if the block is still
free. If so, it can coalesce the 2 blocks.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org4e13401" class="outline-2">
<h2 id="org4e13401"><span class="section-number-2">9</span> Paging</h2>
<div class="outline-text-2" id="text-9">
<p>
Instead of splitting the address space into logical segments, we
split it into fixed-sized units called a <b>page</b>.
</p>

<p>
With paging, physical memory is also split into a number of pages, and
these pages are called <b>page frames</b>.
</p>

<p>
To record where each virtual page of the address place is placed in
physical memory, the OS keeps a <i>per-process</i> data structure known as
a <b>page table</b>. The page table stores <b>address translations</b> for each
of the virtual pages of the address space.
</p>
</div>
<div id="outline-container-org37d4a17" class="outline-3">
<h3 id="org37d4a17"><span class="section-number-3">9.1</span> Address Translation</h3>
<div class="outline-text-3" id="text-9-1">
<p>
To translate a virtual address, the address is split into 2
components:
</p>


<div class="figure">
<p><img src="images/operating_systems/Paging/screenshot_2017-11-05_16-32-30.png" alt="screenshot_2017-11-05_16-32-30.png" />
</p>
</div>

<ol class="org-ol">
<li><b>virtual page number (VPN)</b></li>
<li><b>offset</b> within the page</li>
</ol>

<p>
Suppose the page size is 16 bytes, in a 64-byte address space. We need
to be able to select 4 pages, and the first 2 bits of the address can
do just that, giving us a 2 bit VPN.
</p>
</div>
</div>
<div id="outline-container-org7b07a63" class="outline-3">
<h3 id="org7b07a63"><span class="section-number-3">9.2</span> Inside Page Tables</h3>
<div class="outline-text-3" id="text-9-2">
<p>
The simplest form of a page table is the <b>linear page table</b>, which is
an array. The OS indexes the array by the VPN and looks up the
page-table entry (PTE) at that index in order to find the desired
Physical Frame Number (PFN).
</p>

<p>
Within each PTE, a number of different bits are stored.
</p>

<dl class="org-dl">
<dt>valid bit</dt><dd>indicates whether a particular transaction is valid.
This is crucial for supporting a sparse address space.</dd>
<dt>protection bit</dt><dd>indicating whether a page can be read from,
written to, or executed from.</dd>
<dt>present bit</dt><dd>indicates whether this page is in physical memory or
in disk (swapped out).</dd>
<dt>dirty bit</dt><dd>indicates whether a page has been modified since it was
brought into memory.</dd>
<dt>reference bit</dt><dd>track whether a page has been accessed, and can be
useful in deciding which pages to swap out (e.g.
swapping out the least popular pages).</dd>
</dl>


<div class="figure">
<p><img src="images/operating_systems/Paging/screenshot_2017-11-05_16-38-47.png" alt="screenshot_2017-11-05_16-38-47.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org8eedc9b" class="outline-3">
<h3 id="org8eedc9b"><span class="section-number-3">9.3</span> How Paging Works</h3>
<div class="outline-text-3" id="text-9-3">
<p>
Examine the following instruction: <code>movl 21, %eax</code>. We assume the
hardware performs the translation.
</p>

<ol class="org-ol">
<li>The system fetches the proper page table entry from the process's
page table. To know the location of the page table, the system
looks at the page-table base register, containing the address of
the page table.</li>
<li>The system translates the virtual address (21) to the correct
physical address:</li>
</ol>

<div class="org-src-container">
<pre class="src src-c">VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT
PTEAddr = PageTableBaseRegister + (VPN * sizeof(PTE))
</pre>
</div>

<p>
In this example, <code>VPN_MASK</code> would be set to 0x30, or 110000 in binary,
to extract the VPN bits. Once the PFN is obtained from the page table,
it is left-shifted, and OR'd with the offset to form the final address.
</p>

<p>
Notice each memory reference requires performing one extra memory
reference, which is very costly.
</p>
</div>
</div>
<div id="outline-container-org858ba2b" class="outline-3">
<h3 id="org858ba2b"><span class="section-number-3">9.4</span> Speeding up Paging with TLBs</h3>
<div class="outline-text-3" id="text-9-4">
<p>
Paging alone shows high performance overheads. This is because the
mapping information is generally stored in physical memory, and
requires an extra memory lookup for each virtual memory address.
</p>

<p>
To speed up address translation, a hardware feature called
<b>tranlation-lookaside buffer</b>, or <b>TLB</b>, is added.
</p>

<p>
A TLB is a part of the chip's <b>memory management unit (MMU)</b>, and is a
hardware cache of popular virtual-to-physical address translations.
</p>
</div>
<div id="outline-container-orgef10e12" class="outline-4">
<h4 id="orgef10e12"><span class="section-number-4">9.4.1</span> TLB Basic Algorithm</h4>
<div class="outline-text-4" id="text-9-4-1">
<p>
We first look up the virtual address in the TLB. If it exists in the
TLB, then it is a <b>TLB Hit</b>, and the PFN is extracted from the TLB.
</p>

<p>
If the CPU does not find the translation in the <b>TLB</b>,  this is a
<b>TLB miss</b>. The hardware accesses the page table to find the
translation, and updates the <b>TLB</b>.
</p>

<p>
TLB performance gains benefit from:
</p>

<ol class="org-ol">
<li>Spatial locality: e.g. elements in an array are packed into the
same page, so only the first access is a TLB miss.</li>
<li>Temporal locality: elements accessed recently are more likely to be
accessed again.</li>
</ol>
</div>
</div>
<div id="outline-container-org4339cf9" class="outline-4">
<h4 id="org4339cf9"><span class="section-number-4">9.4.2</span> Managing TLB Misses</h4>
<div class="outline-text-4" id="text-9-4-2">
<p>
Old architectures had hardware -managed TLBs, where the hardware new
exactly where the page tables were located (via registers), the page
table's exact format: the hardware would "walk" the page table and
find the correct page-table entry.
</p>

<p>
Newer architectures have a software-managed TLB. On a TLB miss, the
hardware raises an exception, which pauses the instruction stream,
raises the privilege level to kernel mode, and jumps to a <b>trap
handler</b>.
</p>

<p>
The primary advantage of software-managed TLBs is <i>flexibility</i>. The
OS can use any data structure to implement the page table, without
hardware change. The hardware also doesn't do much on a TLB miss: it
simply raises an exception, and the OS TLB miss handler will handle
the rest.
</p>
</div>
</div>
<div id="outline-container-org9bee52b" class="outline-4">
<h4 id="org9bee52b"><span class="section-number-4">9.4.3</span> Handling Context Switches</h4>
<div class="outline-text-4" id="text-9-4-3">
<p>
The VPN-PFN mapping for different processes are different, and the TLB
will need to account for context switching.
</p>

<p>
One approach is to flush the TLB on context switches. However, each
time a process runs or resumes, it will incur TLB misses.
</p>

<p>
To reduce this overhead, some systems provide an <b>address space
identifier (ASID)</b> in the TLB. the <b>ASID</b> acts as a process
identifier, like the PID but with fewer bits.
</p>


<div class="figure">
<p><img src="images/operating_systems/Paging/screenshot_2017-11-05_19-43-58.png" alt="screenshot_2017-11-05_19-43-58.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org402333f" class="outline-4">
<h4 id="org402333f"><span class="section-number-4">9.4.4</span> TLB Replacement Policies</h4>
<div class="outline-text-4" id="text-9-4-4">
<ol class="org-ol">
<li>Least Recently Used (LRU)
<ul class="org-ul">
<li>takes advantage of locality</li>
</ul></li>
<li>Random
<ul class="org-ul">
<li>no weird corner cases that have pessimal behaviour</li>
</ul></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgbb9caf0" class="outline-3">
<h3 id="orgbb9caf0"><span class="section-number-3">9.5</span> Making Page Tables Smaller</h3>
<div class="outline-text-3" id="text-9-5">
<p>
Simple array-based page tables are too big, taking up too much memory
on physical systems.
</p>
</div>
<div id="outline-container-org79719f0" class="outline-4">
<h4 id="org79719f0"><span class="section-number-4">9.5.1</span> Bigger Pages</h4>
<div class="outline-text-4" id="text-9-5-1">
<p>
Using larger pages will lead to a reduction in the number of page
entries required, and reduce the size of the page table. However, this
leads to a lot of wastage in each page (<b>internal fragmentation</b>).
</p>
</div>
</div>
<div id="outline-container-org998a735" class="outline-4">
<h4 id="org998a735"><span class="section-number-4">9.5.2</span> Paging and Segments</h4>
<div class="outline-text-4" id="text-9-5-2">
<p>
Instead of having a single page table for the entire address space of
the process, have on per logical segment.
</p>

<p>
The virtual address now looks like this: 
</p>


<div class="figure">
<p><img src="images/operating_systems/Paging/screenshot_2017-11-05_19-55-16.png" alt="screenshot_2017-11-05_19-55-16.png" />
</p>
</div>

<p>
The downsides for segmentation apply: segmentation is not flexible,
and if the heap is rarely used, for example, then there is wastage.
</p>
</div>
</div>
<div id="outline-container-org5f777b7" class="outline-4">
<h4 id="org5f777b7"><span class="section-number-4">9.5.3</span> Multi-level Page Tables</h4>
<div class="outline-text-4" id="text-9-5-3">

<div class="figure">
<p><img src="images/operating_systems/Paging/screenshot_2017-11-05_19-57-42.png" alt="screenshot_2017-11-05_19-57-42.png" />
</p>
</div>

<p>
A new data structure called the <b>page directory</b> is introduced. the
page directory consists of a number of <b>page directory entries (PDE)</b>.
A PDE has minimally a <b>valid bit</b> and a <b>page frame number</b>.
</p>

<p>
The page directory only allocates space proportional to the amount of
address space being used, and is generally compact and supports
sparse address spaces.
</p>

<p>
With the page directory, the added <b>level of indirection</b> allows us to
place pages anywhere in physical memory. However, on a TLB miss, two
loads from memory will be required to get the right translation
information from the page table. Hence, there is a <b>time-space</b>
tradeoff.
</p>


<div class="figure">
<p><img src="images/operating_systems/Paging/screenshot_2017-11-05_20-02-30.png" alt="screenshot_2017-11-05_20-02-30.png" />
</p>
</div>

<p>
To extend this idea to multi-level page tables, we can partition the
VPN even further:
</p>


<div class="figure">
<p><img src="images/operating_systems/Paging/screenshot_2017-11-05_20-03-35.png" alt="screenshot_2017-11-05_20-03-35.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org0c403b6" class="outline-4">
<h4 id="org0c403b6"><span class="section-number-4">9.5.4</span> Inverted Page Tables</h4>
<div class="outline-text-4" id="text-9-5-4">
<p>
Instead of having one page table per process, we can have a single
page table for each physical physical page of the system.
</p>

<p>
Finding the correct entry is expensive via a linear scan, and hash
tables are often built over the base structure to speed lookups.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org6d19621" class="outline-2">
<h2 id="org6d19621"><span class="section-number-2">10</span> Beyond Physical Memory</h2>
<div class="outline-text-2" id="text-10">
<p>
Sometimes the address space of a running process does not fit into
memory. In that case, we require an additional level in the memory
hierachy, some place to stash portions of the address space that is
currently not in use. We call this the <b>swap space</b>.
</p>
</div>
<div id="outline-container-orgd8c509f" class="outline-3">
<h3 id="orgd8c509f"><span class="section-number-3">10.1</span> Mechanisms</h3>
<div class="outline-text-3" id="text-10-1">
</div>
<div id="outline-container-org92ec8ac" class="outline-4">
<h4 id="org92ec8ac"><span class="section-number-4">10.1.1</span> Swap Space</h4>
<div class="outline-text-4" id="text-10-1-1">
<p>
<b>Swap space</b> is some space on disk reserved for moving pages back and
forth. The OS will need to memorise the disk address of a given page.
</p>

<p>
The size of the swap space determines the number of pages it can
stash.
</p>
</div>
</div>
<div id="outline-container-org2a59ec4" class="outline-4">
<h4 id="org2a59ec4"><span class="section-number-4">10.1.2</span> The Present Bit</h4>
<div class="outline-text-4" id="text-10-1-2">
<p>
When a TLB miss occurs, the OS will have to look at the swap space
before to find if the page is present in physical memory.
</p>

<p>
When the hardware looks in the PTE, it may find that the page is not
present in physical memory. We have to add one new piece of
information in the PTE, called the <b>present bit</b>. If the present bit
is set to one, then the page is present in physical memory and
everything proceeds as above. If it set to 0, the page is on disk
somewhere. Accessing a page not in physical memory is commonly
referred to as a <b>page fault</b>.
</p>

<p>
Upon a <b>page fault</b>, the OS will run the <b>page-fault handler</b>, and
fetch the page from disk and load it into memory. The OS will then
update the page table to mark the page as present, and update the PFN
field of the PTN to record the in-memory location of the newly fetched
page.
</p>
</div>
</div>
<div id="outline-container-orgdf1951b" class="outline-4">
<h4 id="orgdf1951b"><span class="section-number-4">10.1.3</span> Page-replacement Policy</h4>
<div class="outline-text-4" id="text-10-1-3">
<p>
When memory is full, upon a page fault, the OS will have to decide
which page in the memory to kick out. This replacement policy is known
as the <b>page-replacement policy</b>.
</p>


<p>
Below is the page-fault control algorithm:
</p>

<div class="org-src-container">
<pre class="src src-c">PFN = findFreePhysicalPage();
if (PFN == -1) {                  /* can't find free page */
  PFN = EvictPage();              /* Evict some old page */
 }
DiskRead(PTE.diskAddr, PFN);    /* sleep, waiting for IO */
PTE.present = true;
PTE.PFN = PFN;
RetryInstruction();
</pre>
</div>
</div>
</div>

<div id="outline-container-org87d6fd3" class="outline-4">
<h4 id="org87d6fd3"><span class="section-number-4">10.1.4</span> When Replacements Really Occur</h4>
<div class="outline-text-4" id="text-10-1-4">
<p>
The OS actively keeps a small portion of memory free. To do this, the
OS maintains a <b>high watermark (HW)</b> and a <b>low watermark (LW)</b>. When
the OS notices that there are fewer than LW pages available, a
background thread runs, freeing memory. This is sometimes called a
<b>swap daemon</b> or a <b>page daemon</b>.
</p>

<p>
Many systems cluster a number of pages and write them at once to the
swap partition.
</p>

<p>
With the addition of a <b>page daemon</b>, the control flow algorithm can
be changed. The thread trying to read a page would simply wait for
the page daemon free up enough memory if the LW threshold is hit.
</p>
</div>
</div>
</div>

<div id="outline-container-org5b66b61" class="outline-3">
<h3 id="org5b66b61"><span class="section-number-3">10.2</span> Policies</h3>
<div class="outline-text-3" id="text-10-2">
<p>
The main memory can be viewed as a cache mechanism. Knowing the number
of cache hits and cache misses allows us to calculate the <b>average
memory access time (AMAT)</b> of a program. An optimal page-replacement
policy will reduce the number of cache misses overall. The approach
would be to replace the page that will be accessed furthest in the
future.
</p>

<p>
The first few accesses when the cache begins in an empty state is a
<b>cold-start miss</b>.
</p>
</div>

<div id="outline-container-org15267d0" class="outline-4">
<h4 id="org15267d0"><span class="section-number-4">10.2.1</span> FIFO</h4>
<div class="outline-text-4" id="text-10-2-1">
<p>
In FIFO replacement, pages are placed in a queue when they enter the
system, and when a replacement occurs, the page on the tail of the
queue is evicted.
</p>
</div>

<div id="outline-container-orgca62283" class="outline-5">
<h5 id="orgca62283"><span class="section-number-5">10.2.1.1</span> Belady's anomaly</h5>
<div class="outline-text-5" id="text-10-2-1-1">
<p>
One would normally expect the cache hit rate to increase when the
cache gets larger. However, with FIFO, it gets worse, and this
phenomenon is called <b>Belady's anomaly</b>. LRU has the <b>stack property</b>:
for algorithms with this property, a cache of size N+1 naturally
includes the contents of a cache of size N. FIFO and Random (among
others) do not obey this stack property.
</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Jethro Kuan</p>
<p class="date">Created: 2018-08-15 Wed 11:02</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
